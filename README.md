# HR Agent

<div align="center">

![LangChain](https://img.shields.io/badge/LangChain-0.3+-1e3a5f?style=for-the-badge&logo=langchain&logoColor=white)
![LangGraph](https://img.shields.io/badge/LangGraph-Stateful-3d5a80?style=for-the-badge)
![Langfuse](https://img.shields.io/badge/Langfuse-Tracing-5c7999?style=for-the-badge)
![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![uv](https://img.shields.io/badge/uv-Package_Manager-DE5FE9?style=for-the-badge)

**A production-ready HR assistant demonstrating best practices in LLM agent design**

[Quick Start](#-quick-start) â€¢ [Architecture](#-architecture) â€¢ [Features](#-key-features) â€¢ [Evaluation](#-evaluation)

</div>

---

## ğŸš€ Quick Start

```bash
# Clone and setup
git clone <repository-url>
cd hr-agent

# Install uv (if not already installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install dependencies with uv
uv sync

# Configure
cp .env.example .env
# Edit .env with your LLM API key

# Run the Web UI
uv run streamlit run apps/web/app.py

# Or run the API server
uv run uvicorn apps.api.server:app --reload
```

---

## âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| ğŸ”„ **LangGraph Workflow** | Stateful agent with conditional routing and message history |
| ğŸ› ï¸ **LangChain Tools** | 25 HR tools with Pydantic validation |
| ğŸ“Š **Langfuse Tracing** | Full observability, debugging, and experiment tracking |
| ğŸ” **Policy Authorization** | Declarative YAML-based access control (safe evaluators, no eval()) |
| ğŸ§ª **Evaluation Framework** | 40+ test cases with automated scoring |
| âš¡ **Modern Tooling** | uv for fast dependency management, hatchling for packaging |

---

## ğŸ—ï¸ Architecture

```mermaid
%%{init: {'theme': 'neutral'}}%%
flowchart TB
    subgraph CLIENT["ğŸ–¥ï¸ Clients"]
        WEB["Web UI"]
        CLI["CLI"]
        API["REST API"]
    end
    
    subgraph AGENT["ğŸ¤– LangGraph Agent"]
        direction LR
        LLM["Agent Node"] --> AUTH["Auth Check"]
        AUTH -->|allowed| TOOLS["Tool Execution"]
        AUTH -->|denied| LLM
        TOOLS --> LLM
    end
    
    subgraph SERVICES["âš™ï¸ Services"]
        direction LR
        S1["Employee"]
        S2["Holiday"]
        S3["Compensation"]
    end
    
    subgraph DATA["ğŸ’¾ Data"]
        DB[("Database")]
    end
    
    CLIENT --> AGENT
    AGENT --> SERVICES
    SERVICES --> DATA
```

### How It Works

```mermaid
%%{init: {'theme': 'neutral'}}%%
sequenceDiagram
    participant U as ğŸ‘¤ User
    participant A as ğŸ¤– Agent
    participant P as ğŸ” Policy
    participant T as ğŸ› ï¸ Tools
    participant D as ğŸ’¾ Database

    U->>A: "What's my holiday balance?"
    A->>A: Decide: get_holiday_balance
    A->>P: Check authorization
    P-->>A: âœ… Allowed
    A->>T: Execute tool
    T->>D: Query data
    D-->>T: 15 days remaining
    T-->>A: Result
    A-->>U: "You have 15 vacation days left"
```

---

## ğŸ“ Project Structure

```
hr-agent/
â”œâ”€â”€ ğŸ“ apps/
â”‚   â”œâ”€â”€ web/                     # Streamlit Web UI
â”‚   â””â”€â”€ api/                     # FastAPI server
â”‚
â”œâ”€â”€ ğŸ“ hr_agent/
â”‚   â”œâ”€â”€ agent/                   # LangGraph workflow
â”‚   â”œâ”€â”€ policies/                # Authorization + YAML rules
â”‚   â”œâ”€â”€ tools/                   # LangChain tool wrappers
â”‚   â”œâ”€â”€ services/                # Business logic
â”‚   â”œâ”€â”€ repositories/            # Data access layer
â”‚   â”œâ”€â”€ configs/                 # Configuration
â”‚   â”œâ”€â”€ tracing/                 # Observability
â”‚   â””â”€â”€ utils/                   # Cross-cutting utilities
â”‚
â”œâ”€â”€ ğŸ“ evals/                    # Evaluation framework
â””â”€â”€ ğŸ“ docs/                     # Architecture and evaluation docs
```

---

## ğŸ§ª Evaluation

```bash
# Quick test (10 cases)
python evals/runners/run_evals.py --quick --verbose

# Full evaluation
python evals/runners/run_evals.py

# Filter by category
python evals/runners/run_evals.py --category time_off
```

### Sample Output

```
======================================================================
  ğŸ“Š EVALUATION RESULTS
======================================================================
  Total Cases:      40
  Passed:           38 / 40
  Pass Rate:        95.0%

  Accuracy Metrics
  ----------------------------------------
  Tool Selection     97.5%
  Answer Quality     95.0%
  Authorization      100.0%
======================================================================
```

---

## ğŸ› ï¸ Available Tools

```mermaid
%%{init: {'theme': 'neutral'}}%%
mindmap
  root((ğŸ› ï¸ HR Tools))
    ğŸ‘¤ Employee
      search_employee
      get_employee_basic
      get_employee_tenure
    ğŸ¢ Organization
      get_manager
      get_direct_reports
      get_org_chart
      get_department_directory
    ğŸ–ï¸ Time Off
      get_holiday_balance
      submit_holiday_request
      get_pending_approvals
      get_team_calendar
    ğŸ’° Compensation
      get_compensation
      get_salary_history
    ğŸ“‹ Company
      get_company_policies
      get_announcements
      get_company_holidays
```

---

## âš™ï¸ Configuration

```bash
# .env

# LLM Provider
LLM_PROVIDER=openai_compatible
LLM_API_KEY=sk-...
LLM_MODEL=gpt-4o-mini

# Optional: Langfuse Observability (free tier available)
LANGFUSE_ENABLED=true
LANGFUSE_PUBLIC_KEY=pk-...
LANGFUSE_SECRET_KEY=sk-...
LANGFUSE_HOST=https://cloud.langfuse.com

# Langfuse eval tracing
# Eval runs are tagged with metadata like run_type=eval and eval_dataset=<name>

```

### Using uv

```bash
# Install dependencies
uv sync

# Install with dev dependencies
uv sync --group dev

# Run commands
uv run streamlit run apps/web/app.py
uv run pytest
uv run ruff check .
```

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| [ARCHITECTURE.md](ARCHITECTURE.md) | Technical architecture, diagrams, design decisions |
| [EVALUATION.md](EVALUATION.md) | Evaluation framework, metrics, test cases |

---

## ğŸ“„ License

MIT
